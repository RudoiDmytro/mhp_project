{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91306721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 22:50:29 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Stanza pipeline for Ukrainian...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 4.51MB/s]                    \n",
      "2025-09-30 22:50:29 WARNING: Language uk package default expects mwt, which has been added\n",
      "2025-09-30 22:50:29 INFO: Loading these models for language: uk (Ukrainian):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | iu          |\n",
      "| mwt       | iu          |\n",
      "| lemma     | iu_nocharlm |\n",
      "===========================\n",
      "\n",
      "2025-09-30 22:50:29 INFO: Using device: cpu\n",
      "2025-09-30 22:50:29 INFO: Loading: tokenize\n",
      "2025-09-30 22:50:29 INFO: Loading: mwt\n",
      "2025-09-30 22:50:29 INFO: Loading: lemma\n",
      "2025-09-30 22:50:30 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza pipeline initialized.\n",
      "Step 1: Loading and cleaning data...\n",
      "Step 2: Preprocessing titles with Stanza...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing titles: 100%|██████████| 13199/13199 [03:54<00:00, 56.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Training or loading Word2Vec model...\n",
      "Training Word2Vec model... (this may take a few minutes)\n",
      "Model trained and saved to ./word2vec_rada_stanza.model\n",
      "\n",
      "Step 4: Analyzing keywords to find nearest neighbors...\n",
      "\n",
      "--- ANALYSIS RESULTS ---\n",
      "\n",
      "--- Категорія: АГРАРНА ---\n",
      "  Для 'сільськогосподарський': фермерський (0.98), регіональний (0.98), майбутній (0.97), машинобудування (0.97), вугільна (0.97), оператор (0.97), ціль (0.97), пенсійна (0.97), напрям (0.97), інформаційна (0.97)\n",
      "  Для 'оренда': приватизація (0.98), комунальний (0.96), передача (0.91), майна (0.89), майний (0.89), природнозаповідне (0.89), обєкт (0.87), державні (0.87), земля (0.87), вугледобувний (0.87)\n",
      "  Для 'земельний': ділянка (0.97), земля (0.91), розбудова (0.85), продаж (0.84), інфраструктури (0.83), відведення (0.83), сільськогосподарського (0.81), комунальний (0.81), цифровати (0.80), передача (0.80)\n",
      "  Для 'фермерський': машинобудування (0.98), сільськогосподарський (0.98), меліорація (0.98), гідротехнічний (0.98), рідкий (0.98), напрям (0.98), виділення (0.98), біопалива (0.97), турити (0.97), глобальний (0.97)\n",
      "  Для 'аграрний': продовольство (0.97), молодіжний (0.97), науковотехнічний (0.94), загальнодержавна (0.94), промисловість (0.94), сталий (0.94), зовнішній (0.93), засади (0.93), водний (0.93), регіональний (0.93)\n",
      "  Для 'земля': сільськогосподарського (0.92), земельний (0.91), цільовий (0.91), ділянка (0.90), природнозаповідне (0.90), розбудова (0.88), оренда (0.87), відведення (0.86), обороннопомислове (0.86), приватизація (0.85)\n",
      "  Для 'субсидія': (не знайдено близьких слів у моделі)\n",
      "  Для 'квота': (не знайдено близьких слів у моделі)\n",
      "  Для 'експортний': перегляд (0.96), екологічного (0.95), диференційований (0.94), ставок (0.94), кредитування (0.94), звітність (0.93), товарний (0.93), інститут (0.93), обороннути (0.93), спрощений (0.92)\n",
      "  Для 'фітосанітарний': (не знайдено близьких слів у моделі)\n",
      "  Для 'ринок': електрична (0.95), енергія (0.94), газ (0.91), природний (0.89), альтернативний (0.88), теплова (0.87), накопичення (0.86), постачання (0.85), виробництво (0.84), деревини (0.83)\n",
      "\n",
      "--- Категорія: СОЦІАЛЬНА ---\n",
      "  Для 'пенсійний': зайнятість (0.95), гарантування (0.93), пенсій (0.93), загальнообовязяове (0.92), випадок (0.92), прожитковий (0.91), малозабезпечене (0.90), комплектування (0.90), мінімальний (0.90), збільшення (0.90)\n",
      "  Для 'соціальний': захищеність (0.90), гарантія (0.88), зайнятість (0.88), ветеран (0.88), пенсійний (0.86), загальнообовязяове (0.85), дітейсиріт (0.85), гарант (0.84), немайновий (0.83), військовослужбовець (0.83)\n",
      "  Для 'профспілка': незначний (0.96), спосіб (0.96), складності (0.95), типовий (0.95), необхідний (0.94), відпустка (0.94), фіскальний (0.94), поліцейський (0.94), жити (0.94), дані (0.94)\n",
      "  Для 'трудовий': сприятливий (0.93), правовідносин (0.91), ведення (0.91), парки (0.91), повязана (0.91), конопель (0.91), підприємницька (0.90), ціноутворення (0.90), відносин (0.89), залучення (0.89)\n",
      "  Для 'внесок': учений (0.96), дата (0.95), ювіл (0.95), відзначення (0.94), черговий (0.94), премія (0.93), памятни (0.93), додаток (0.92), 13р2020 (0.92), фінанси (0.92)\n",
      "  Для 'охорона': здоровя (0.95), сфера (0.85), обслуговування (0.81), психічний (0.81), навколишнє (0.80), громадське (0.80), інтелектуальний (0.80), пасажирський (0.79), енергетики (0.78), матеріальнотехнеї (0.77)\n",
      "  Для 'праця': оплата (0.95), гуманітарн (0.89), розширення (0.87), дитинство (0.86), гідний (0.83), рівний (0.83), проїзд (0.83), 233 (0.82), психологічний (0.82), можливість (0.81)\n",
      "  Для 'зайнятість': пенсійний (0.95), випадок (0.95), продуктивній (0.92), екстрений (0.91), норматив (0.91), пенсійне (0.91), семь (0.90), загальнообовязяове (0.90), захисна (0.90), жити (0.90)\n",
      "\n",
      "--- Категорія: КОРПОРАТИВНА ---\n",
      "  Для 'оподаткування': податок (0.93), платник (0.92), додан (0.92), вартість (0.91), справляння (0.89), акцизний (0.88), ставка (0.86), адміністрування (0.85), мит (0.85), податковий (0.85)\n",
      "  Для 'ПДВ': (не знайдено близьких слів у моделі)\n",
      "  Для 'та': (не знайдено близьких слів у моделі)\n",
      "  Для 'податок': платник (0.97), додан (0.94), вартість (0.93), оподаткування (0.93), акцизний (0.93), дохід (0.92), ставка (0.90), 29052024 (0.89), справляння (0.88), сплата (0.88)\n",
      "  Для 'папери': (не знайдено близьких слів у моделі)\n",
      "  Для 'корпоративний': (не знайдено близьких слів у моделі)\n",
      "  Для 'акціонерний': (не знайдено близьких слів у моделі)\n",
      "  Для 'поглинання': (не знайдено близьких слів у моделі)\n",
      "  Для 'злиття': (не знайдено близьких слів у моделі)\n",
      "  Для 'цінний': організованаю (0.87), телебачення (0.85), виборч (0.84), звіт (0.83), конкурснат (0.83), антидопінговий (0.82), радіомовлення (0.82), агентство (0.82), комісія (0.82), наділення (0.81)\n",
      "  Для 'валютний': пестицид (0.98), насіння (0.98), поза (0.98), вино (0.98), напад (0.98), дефіцит (0.97), клінічний (0.97), загальнодержавне (0.97), біопалива (0.97), паливо (0.97)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import stanza\n",
    "\n",
    "DATA_FILE_PATH = './billinfo-skl9.json' \n",
    "MODEL_FILE_PATH = './word2vec_rada_stanza.model'\n",
    "SEED_KEYWORDS = {\n",
    "    'Аграрна': ['земельний', 'субсидія', 'експортний', 'квота', 'фітосанітарний', 'ринок землі', 'сільськогосподарський', 'аграрний', 'фермерський', 'оренда землі'],\n",
    "    'Соціальна': ['трудовий', 'соціальний', 'пенсійний', 'охорона праці', 'зайнятість', 'профспілка', 'внесок'],\n",
    "    'Корпоративна': ['оподаткування', 'податок', 'валютний', 'корпоративний', 'акціонерний', 'цінні папери', 'злиття та поглинання', 'ПДВ']\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"Initializing Stanza pipeline for Ukrainian...\")\n",
    "    nlp = stanza.Pipeline('uk', processors='tokenize,lemma')\n",
    "    print(\"Stanza pipeline initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize Stanza. It might be downloading the model. Error: {e}\")\n",
    "    print(\"Downloading the Stanza model for Ukrainian ('uk')...\")\n",
    "    stanza.download('uk')\n",
    "    nlp = stanza.Pipeline('uk', processors='tokenize,lemma')\n",
    "    print(\"Stanza pipeline initialized after download.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "ukrainian_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "custom_stopwords = ['проект', 'закон', 'україна', 'щодо', 'про', 'внесення', 'зміна', 'до', 'деякий', 'акт', 'кодекс']\n",
    "ukrainian_stopwords.extend(custom_stopwords)\n",
    "\n",
    "\n",
    "def preprocess_text_stanza(text, nlp_pipeline):\n",
    "    \"\"\"Очищує та лематизує текст за допомогою Stanza.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    doc = nlp_pipeline(text)\n",
    "    lemmatized_tokens = [\n",
    "        word.lemma \n",
    "        for sent in doc.sentences for word in sent.words\n",
    "        if word.lemma not in ukrainian_stopwords and len(word.lemma) > 2\n",
    "    ]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "\n",
    "def train_or_load_model(processed_titles):\n",
    "    \"\"\"Тренує модель Word2Vec або завантажує, якщо вона вже існує.\"\"\"\n",
    "    if os.path.exists(MODEL_FILE_PATH):\n",
    "        print(f\"Loading existing model from {MODEL_FILE_PATH}...\")\n",
    "        model = Word2Vec.load(MODEL_FILE_PATH)\n",
    "        return model\n",
    "    \n",
    "    print(\"Training Word2Vec model... (this may take a few minutes)\")\n",
    "    model = Word2Vec(sentences=processed_titles, vector_size=150, window=5, min_count=5, workers=4)\n",
    "    model.save(MODEL_FILE_PATH)\n",
    "    print(f\"Model trained and saved to {MODEL_FILE_PATH}\")\n",
    "    return model\n",
    "\n",
    "def find_related_keywords(model, seed_keywords, top_n=10):\n",
    "    \"\"\"Знаходить семантично близькі слова.\"\"\"\n",
    "    analysis_results = {}\n",
    "    for category, keywords in seed_keywords.items():\n",
    "        analysis_results[category] = {}\n",
    "        doc = nlp(\" \".join(keywords))\n",
    "        lemmatized_keywords = {word.lemma for sent in doc.sentences for word in sent.words}\n",
    "        \n",
    "        for keyword in lemmatized_keywords:\n",
    "            if keyword in model.wv:\n",
    "                similar_words = model.wv.most_similar(keyword, topn=top_n)\n",
    "                analysis_results[category][keyword] = similar_words\n",
    "            else:\n",
    "                analysis_results[category][keyword] = []\n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Step 1: Loading and cleaning data...\")\n",
    "    try:\n",
    "        with open(DATA_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "        \n",
    "        cleaned_text = re.sub(r'[\\x00-\\x1F]', ' ', raw_text)\n",
    "        \n",
    "        data = json.loads(cleaned_text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Data file not found at {DATA_FILE_PATH}\")\n",
    "        return\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ERROR: Failed to parse JSON even after cleaning. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    titles = [item['name'] for item in data if 'name' in item and item['name']]\n",
    "    \n",
    "    print(\"Step 2: Preprocessing titles with Stanza...\")\n",
    "    processed_titles = [preprocess_text_stanza(title, nlp) for title in tqdm(titles, desc=\"Preprocessing titles\")]\n",
    "    \n",
    "    print(\"\\nStep 3: Training or loading Word2Vec model...\")\n",
    "    model = train_or_load_model(processed_titles)\n",
    "    \n",
    "    print(\"\\nStep 4: Analyzing keywords to find nearest neighbors...\")\n",
    "    analysis_results = find_related_keywords(model, SEED_KEYWORDS)\n",
    "    \n",
    "    print(\"\\n--- ANALYSIS RESULTS ---\")\n",
    "    for category, keywords_data in analysis_results.items():\n",
    "        print(f\"\\n--- Категорія: {category.upper()} ---\")\n",
    "        for seed_word, suggestions in keywords_data.items():\n",
    "            if suggestions:\n",
    "                suggested_list = [f\"{word} ({score:.2f})\" for word, score in suggestions]\n",
    "                print(f\"  Для '{seed_word}': {', '.join(suggested_list)}\")\n",
    "            else:\n",
    "                print(f\"  Для '{seed_word}': (не знайдено близьких слів у моделі)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
